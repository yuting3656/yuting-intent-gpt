{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5423de5b-56f9-4129-9cb8-d80bfd0698d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044f3309-2a20-4509-ab39-635440e5a38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[text for text, label in train_data] ['今天工廠整場表現', '哪幾台產出最多良品', '有哪些機台異常？', '哪些工單會遲交', '請問 小王 今天表現如何', '請問 小明 這週表現如何']\n",
      "train_sequences [[2], [3], [4], [5], [1, 6, 7], [1, 8, 9]]\n",
      "Train on 6 samples\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 162ms/sample - loss: 1.6095 - accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 683us/sample - loss: 1.6045 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.6001 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 835us/sample - loss: 1.5955 - accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 882us/sample - loss: 1.5908 - accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 962us/sample - loss: 1.5855 - accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 842us/sample - loss: 1.5795 - accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 682us/sample - loss: 1.5724 - accuracy: 0.3333\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.5648 - accuracy: 0.3333\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.5557 - accuracy: 0.3333\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 1.5455 - accuracy: 0.3333\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.5336 - accuracy: 0.3333\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 686us/sample - loss: 1.5196 - accuracy: 0.3333\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 982us/sample - loss: 1.5036 - accuracy: 0.3333\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 974us/sample - loss: 1.4850 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 821us/sample - loss: 1.4639 - accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 889us/sample - loss: 1.4404 - accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 927us/sample - loss: 1.4135 - accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 846us/sample - loss: 1.3832 - accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 785us/sample - loss: 1.3496 - accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.3121 - accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 865us/sample - loss: 1.2707 - accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 859us/sample - loss: 1.2253 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 959us/sample - loss: 1.1766 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 830us/sample - loss: 1.1261 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 907us/sample - loss: 1.0748 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 987us/sample - loss: 1.0237 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 772us/sample - loss: 0.9747 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 862us/sample - loss: 0.9287 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 877us/sample - loss: 0.8858 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 804us/sample - loss: 0.8465 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 915us/sample - loss: 0.8084 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 825us/sample - loss: 0.7708 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 896us/sample - loss: 0.7336 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 749us/sample - loss: 0.6947 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.6560 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 906us/sample - loss: 0.6138 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 955us/sample - loss: 0.5722 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 804us/sample - loss: 0.5294 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 977us/sample - loss: 0.4865 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.4442 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 972us/sample - loss: 0.4011 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 885us/sample - loss: 0.3608 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.3204 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 813us/sample - loss: 0.2827 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.2464 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 988us/sample - loss: 0.2133 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 837us/sample - loss: 0.1824 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.1529 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 678us/sample - loss: 0.1271 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 956us/sample - loss: 0.1043 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0846 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0661 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 935us/sample - loss: 0.0507 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0387 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 973us/sample - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 914us/sample - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 864us/sample - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 827us/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 976us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 844us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 950us/sample - loss: 9.3800e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 8.5604e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 7.8729e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 857us/sample - loss: 7.2878e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 6.7826e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 6.3420e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 811us/sample - loss: 5.9523e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 5.6064e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 952us/sample - loss: 5.2998e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 5.0236e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 4.7742e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 3ms/sample - loss: 4.5476e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 2ms/sample - loss: 4.3419e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 952us/sample - loss: 4.1556e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 3.9878e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 881us/sample - loss: 3.8355e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 761us/sample - loss: 3.6959e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 826us/sample - loss: 3.5678e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 3.4504e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 703us/sample - loss: 3.3416e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 684us/sample - loss: 3.2403e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 867us/sample - loss: 3.1461e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 617us/sample - loss: 3.0583e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 626us/sample - loss: 2.9761e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 762us/sample - loss: 2.8997e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 628us/sample - loss: 2.8285e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 690us/sample - loss: 2.7612e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 758us/sample - loss: 2.6985e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 694us/sample - loss: 2.6411e-04 - accuracy: 1.0000\n",
      "4/1 [========================================================================================================================] - 0s 50ms/sample - loss: 4.7528 - accuracy: 0.2500\n",
      "Test Loss: 4.752800941467285, Test Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Define the intent labels\n",
    "labels = [\"效率\", \"良率\", \"時間\",\"機台\", \"員工\"]\n",
    "\n",
    "# Define the training data\n",
    "train_data = [\n",
    "    (\"今天工廠整場表現\", \"效率\"),\n",
    "    (\"哪幾台產出最多良品\", \"良率\"),\n",
    "    (\"有哪些機台異常？\", \"機台\"),\n",
    "    (\"哪些工單會遲交\", \"時間\"),\n",
    "    (\"請問 小王 今天表現如何\", \"員工\"),\n",
    "    (\"請問 小明 這週表現如何\", \"員工\")\n",
    "]\n",
    "\n",
    "# Tokenize the training data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text for text, label in train_data])\n",
    "\n",
    "# Convert the training data to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences([text for text, label in train_data])\n",
    "print(\"[text for text, label in train_data]\", [text for text, label in train_data])\n",
    "print(\"train_sequences\", train_sequences)\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = max(len(seq) for seq in train_sequences)\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Convert the labels to one-hot encodings\n",
    "label_encoder = {label: i for i, label in enumerate(labels)}\n",
    "train_labels = [label_encoder[label] for text, label in train_data]\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=len(labels))\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=32, input_length=max_length))\n",
    "model.add(layers.Conv1D(64, 5, activation='relu', padding=\"same\"))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(len(labels), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_sequences, train_labels, epochs=100)\n",
    "\n",
    "# Evaluate the model\n",
    "test_data = [\n",
    "    (\"今天有 Gp122. 來的急出貨嗎？\", \"時間\"),\n",
    "    (\"阿華工作進度如何\", \"員工\"),\n",
    "    (\"機台 H122 怎麼沒在動 \", \"機台\"),\n",
    "    (\"事不是可以提高訂單量\", \"效率\")\n",
    "]\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences([text for text, label in test_data])\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "test_labels = [label_encoder[label] for text, label in test_data]\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=len(labels))\n",
    "\n",
    "loss, accuracy = model.evaluate(test_sequences, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5668bac-6fa3-4c80-a681-e2ec7ca7fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 3, 32)             320       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 3, 64)             10304     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 33,605\n",
      "Trainable params: 33,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9261c6ad-e1bf-4178-a5ec-f6a766e38d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = \"請問 陳先生表現如合？\"\n",
    "sequence_input = tokenizer.texts_to_sequences([questions])\n",
    "padded_input = pad_sequences(sequence_input, maxlen=max_length , padding=\"post\")\n",
    "padded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27ab0e9d-4654-475e-924f-0e46b2e51fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(padded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa27ec7e-9805-4186-ac0a-f33cf6c7601d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1739888e-02, 4.5997676e-04, 4.6455115e-03, 9.8133296e-01,\n",
       "        1.8216027e-03]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4cddb95-747f-46e0-992e-e2edc73282a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label 機台\n"
     ]
    }
   ],
   "source": [
    "predicted_probs = model.predict(padded_input)[0]\n",
    "predicted_label_index = np.argmax(result)\n",
    "\n",
    "\n",
    "if predicted_probs[predicted_label_index] < 0.9:\n",
    "    print(\"老賽！\")\n",
    "else:\n",
    "    predicted_label = labels[predicted_label_index]\n",
    "    print(\"predicted_label\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20987a-eedd-41df-9b6a-8c36c0a508a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dzGPT",
   "language": "python",
   "name": "dzgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
