{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5423de5b-56f9-4129-9cb8-d80bfd0698d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 16:42:36.882056: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044f3309-2a20-4509-ab39-635440e5a38e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[text for text, label in train_data] ['今天工廠整場表現', '哪幾台產出最多良品', '有哪些機台異常？', '哪些工單會遲交', '請問 小王 今天表現如何', '請問 小明 這週表現如何']\n",
      "train_sequences [[2], [3], [4], [5], [1, 6, 7], [1, 8, 9]]\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 16:42:40.000483: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.6102 - accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6064 - accuracy: 0.1667\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6028 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5988 - accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5942 - accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5892 - accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5835 - accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5771 - accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5703 - accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5625 - accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5536 - accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5434 - accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5320 - accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5189 - accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5040 - accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4871 - accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4677 - accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4463 - accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4221 - accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3946 - accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3642 - accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3303 - accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2922 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2504 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2037 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1535 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0984 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0394 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9779 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9144 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8493 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7834 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7194 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6557 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3091 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2716 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2404 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1852 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1652 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1104 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7348e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1761e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9742e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.0342e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.2853e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6853e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2082e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8133e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.4823e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2020e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9645e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7596e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5830e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4287e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2946e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1774e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0740e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9832e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9037e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8326e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7681e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7101e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6578e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6100e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5663e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5263e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4896e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4558e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4252e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3960e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3696e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3442e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 4.6233 - accuracy: 0.2500\n",
      "Test Loss: 4.623340129852295, Test Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Define the intent labels\n",
    "labels = [\"效率\", \"良率\", \"時間\",\"機台\", \"員工\"]\n",
    "\n",
    "# Define the training data\n",
    "train_data = [\n",
    "    (\"今天工廠整場表現\", \"效率\"),\n",
    "    (\"哪幾台產出最多良品\", \"良率\"),\n",
    "    (\"有哪些機台異常？\", \"機台\"),\n",
    "    (\"哪些工單會遲交\", \"時間\"),\n",
    "    (\"請問 小王 今天表現如何\", \"員工\"),\n",
    "    (\"請問 小明 這週表現如何\", \"員工\")\n",
    "]\n",
    "\n",
    "# Tokenize the training data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text for text, label in train_data])\n",
    "\n",
    "# Convert the training data to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences([text for text, label in train_data])\n",
    "print(\"[text for text, label in train_data]\", [text for text, label in train_data])\n",
    "print(\"train_sequences\", train_sequences)\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = max(len(seq) for seq in train_sequences)\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Convert the labels to one-hot encodings\n",
    "label_encoder = {label: i for i, label in enumerate(labels)}\n",
    "train_labels = [label_encoder[label] for text, label in train_data]\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=len(labels))\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=32, input_length=max_length))\n",
    "model.add(layers.Conv1D(64, 5, activation='relu', padding=\"same\"))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(len(labels), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_sequences, train_labels, epochs=100)\n",
    "\n",
    "# Evaluate the model\n",
    "test_data = [\n",
    "    (\"今天有 Gp122. 來的急出貨嗎？\", \"時間\"),\n",
    "    (\"阿華工作進度如何\", \"員工\"),\n",
    "    (\"機台 H122 怎麼沒在動 \", \"機台\"),\n",
    "    (\"事不是可以提高訂單量\", \"效率\")\n",
    "]\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences([text for text, label in test_data])\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "test_labels = [label_encoder[label] for text, label in test_data]\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=len(labels))\n",
    "\n",
    "loss, accuracy = model.evaluate(test_sequences, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5668bac-6fa3-4c80-a681-e2ec7ca7fd5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 32)             320       \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 3, 64)             10304     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,605\n",
      "Trainable params: 33,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9261c6ad-e1bf-4178-a5ec-f6a766e38d53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = \"請問 陳先生表現如合？\"\n",
    "sequence_input = tokenizer.texts_to_sequences([questions])\n",
    "padded_input = pad_sequences(sequence_input, maxlen=max_length , padding=\"post\")\n",
    "padded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ab0e9d-4654-475e-924f-0e46b2e51fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(padded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa27ec7e-9805-4186-ac0a-f33cf6c7601d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00700853, 0.17302732, 0.5845128 , 0.21982652, 0.01562475]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4cddb95-747f-46e0-992e-e2edc73282a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "老賽！\n"
     ]
    }
   ],
   "source": [
    "predicted_probs = model.predict(padded_input)[0]\n",
    "predicted_label_index = np.argmax(result)\n",
    "\n",
    "\n",
    "if predicted_probs[predicted_label_index] < 0.9:\n",
    "    print(\"老賽！\")\n",
    "else:\n",
    "    predicted_label = labels[predicted_label_index]\n",
    "    print(\"predicted_label\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20987a-eedd-41df-9b6a-8c36c0a508a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dzGPT",
   "language": "python",
   "name": "dzgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
